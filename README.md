# ğŸ§© LLM Evaluation & Guardrails â€” Notebook Version

![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Jupyter](https://img.shields.io/badge/Notebook-Ready-orange)

A single Jupyter Notebook to **evaluate**, **analyze**, and **stress-test** Large Language Models (LLMs).  
This project includes **metrics**, **PII detection**, **red teaming**, and **visual analytics** â€” all in one lightweight file.

---

## ğŸš€ Overview

**LLM Evaluation & Guardrails** provides a minimal yet powerful framework to test how reliable, safe, and robust a model is.  
It helps you measure **accuracy**, **PII safety**, and **robustness** with a simple notebook interface.

### âœ¨ Features
- ğŸ“Š **Metrics:** Exact Match (EM), token-level F1, latency tracking  
- ğŸ” **PII Detection:** regex-based checks for emails, phone numbers, and IBAN-like patterns  
- ğŸ§¨ **Red Teaming:** jailbreak and adversarial prompt testing  
- âš¡ **Plug-and-Play LLM Client:** compatible with Ollama (local), HTTP APIs, or mock mode  
- ğŸ“ˆ **Visualization:** charts for accuracy and latency  
- ğŸ’¾ **Export:** save results as `.csv` and `.json` for later analysis  

---

## ğŸ§  Motivation

Modern LLMs are powerful â€” but how **safe** and **consistent** are they?  
This notebook lets you locally benchmark any LLM, detect privacy leaks, and probe robustness without complex setup.

Perfect for:
- ğŸ¤– AI / ML engineers  
- ğŸ“ Students & researchers in NLP or AI safety  
- ğŸ§ª Developers testing local or hosted LLMs  

---

## ğŸ“ Project Structure

llm-eval-guardrails/
â”œâ”€â”€ llm_eval_guardrails.ipynb # Main notebook
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ .env.example # Example environment config
â”œâ”€â”€ .gitignore # Ignore virtualenv & secrets
â”‚
â”œâ”€â”€ artifacts/ # Output results
â”‚ â”œâ”€â”€ results.csv
â”‚ â””â”€â”€ results.json
â”‚
â”œâ”€â”€ assets/ # (Optional) images for README
â”‚ â”œâ”€â”€ dashboard.png
â”‚ â””â”€â”€ latency_chart.png
â”‚
â””â”€â”€ data/ # (Optional) test examples
â”œâ”€â”€ sample_tests.json
â””â”€â”€ redteam_prompts.txt
---
